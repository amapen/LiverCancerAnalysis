{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy.special import ndtri\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-opposition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('データ抽出.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-intelligence",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('データ抽出.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-syndication",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-smoke",
   "metadata": {},
   "source": [
    "## 治療法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['治療法解析用'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['治療法解析用'].isnull().sum()\n",
    "df['治療法解析用'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['治療法解析用'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['治療法解析用'], prefix='', prefix_sep='')\n",
    "df = df.drop(columns='無治療')\n",
    "df.rename(columns={'化学療法': 'MTA', '放射線治療': 'Radiation'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-expansion",
   "metadata": {},
   "source": [
    "## 前回治療からの期間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['Last_Treatment'].isnull().sum()\n",
    "df['Last_Treatment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_Treatment'] = df['Last_Treatment'].replace('#NUM!', 0).replace(0, 10000).astype(int)\n",
    "df['Last_Treatment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_Treatment'] = np.log10(df['Last_Treatment'] + 1)\n",
    "df['Last_Treatment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-masters",
   "metadata": {},
   "source": [
    "## 年齢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['Age'].isnull().sum()\n",
    "df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-allowance",
   "metadata": {},
   "source": [
    "## 性別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['Gender'].isnull().sum()\n",
    "df['Gender'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace(1,  0).replace(2, 1)\n",
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-corruption",
   "metadata": {},
   "source": [
    "## BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BMI'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BMI'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-democrat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['BMI_NN'] = df['BMI'].fillna(df['BMI'].mean())\n",
    "df['BMI_NN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-mother",
   "metadata": {},
   "source": [
    "## 手術回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['No_of_Admission'].isnull().sum()\n",
    "df['No_of_Admission'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['No_of_Admission'])\n",
    "df['No_of_Admission'] = df['No_of_Admission'].astype(int)\n",
    "df['No_of_Admission'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-oregon",
   "metadata": {},
   "source": [
    "## 個数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HCC_No'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['HCC_No'].isnull().sum()\n",
    "df['HCC_No'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['HCC_No'] = df['HCC_No'].fillna(5).astype(int)\n",
    "df = df.dropna(subset=['HCC_No'])\n",
    "df['HCC_No'] = df['HCC_No'].astype(int)\n",
    "df['HCC_No'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = 0\n",
    "l = []\n",
    "for i, n in zip(df['Code'], df['HCC_No']):\n",
    "    if i == before:\n",
    "        l.append(l[-1] + n)\n",
    "    else:\n",
    "        l.append(n)\n",
    "        before = i\n",
    "\n",
    "df['No_Cumsum'] = l\n",
    "df['No_Cumsum'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-oxide",
   "metadata": {},
   "source": [
    "## サイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HCC_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['HCC_size'].isnull().sum()\n",
    "df['HCC_size'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('diffuse', '1')\n",
    "df = df.dropna(subset=['HCC_size'])\n",
    "df['HCC_size'] = df['HCC_size'].map(lambda x: int(Decimal(str(x)).quantize(Decimal('0'), rounding=ROUND_HALF_UP)))\n",
    "df['HCC_size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-consultation",
   "metadata": {},
   "source": [
    "## サイズ*個数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NoSize'] = df['HCC_No'] * df['HCC_size']\n",
    "df['NoSize'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['NoSize'].isnull().sum()\n",
    "df['NoSize'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = 0\n",
    "l = []\n",
    "for i, n in zip(df['Code'], df['NoSize']):\n",
    "    if i == before:\n",
    "        l.append(l[-1] + n)\n",
    "    else:\n",
    "        l.append(n)\n",
    "        before = i\n",
    "\n",
    "l_10 = [i//10 for i in l]\n",
    "df['NoSize_Cumsum'] = l_10\n",
    "df['NoSize_Cumsum'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-study",
   "metadata": {},
   "source": [
    "## PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSは0埋め\n",
    "df['PS_Raw'] = df['PS'].fillna(0).astype(int)\n",
    "df['PS_Raw'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-plumbing",
   "metadata": {},
   "source": [
    "## ALBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALBI_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['ALBI_score'].isnull().sum()\n",
    "df['ALBI_score'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['ALBI_score'])\n",
    "df['ALBI_score'] = df['ALBI_score'].map(lambda x: int(Decimal(str(x*(-100))).quantize(Decimal('0'), rounding=ROUND_HALF_UP)))\n",
    "df['ALBI_score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-scott",
   "metadata": {},
   "source": [
    "## ALBI_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALBI_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['ALBI_grade'].isnull().sum()\n",
    "df['ALBI_grade'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALBI_grade'] = df['ALBI_grade'].replace('3', '4').replace('2b', '3').replace('2a', '2').astype(int)\n",
    "df = pd.get_dummies(df, columns=['ALBI_grade'])\n",
    "df = df.drop(columns='ALBI_grade_1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-quarterly",
   "metadata": {},
   "source": [
    "## AFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut += df['AFP'].isnull().sum()\n",
    "df['AFP'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFPは0埋め\n",
    "df['AFP'] = df['AFP'].fillna(0).astype(float)\n",
    "df.insert(loc=0, column='AFP_100', value= -1)\n",
    "df.loc[df['AFP'] < 100, 'AFP_100'] = 0\n",
    "df.loc[~(df['AFP'] < 100), 'AFP_100'] = 1\n",
    "df['AFP_100'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-switzerland",
   "metadata": {},
   "source": [
    "## L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut += df['L3'].isnull().sum()\n",
    "df['L3'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L3は0埋め\n",
    "df['L3'] = df['L3'].fillna(0).astype(float)\n",
    "df.insert(loc=0, column='L3_10', value= -1)\n",
    "df.loc[df['L3'] < 10, 'L3_10'] = 0\n",
    "df.loc[~(df['L3'] < 10), 'L3_10'] = 1\n",
    "df['L3_10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['L3_10'] = df['L3_10'].fillna(0).astype(int)\n",
    "df['L3_10'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-avatar",
   "metadata": {},
   "source": [
    "## PIVKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut += df['PIVKA'].isnull().sum()\n",
    "df['PIVKA'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIVKAは0埋め\n",
    "df['PIVKA'] = df['PIVKA'].fillna(0).astype(float)\n",
    "df.insert(loc=0, column='PIVKA_100', value= -1)\n",
    "df.loc[df['PIVKA'] < 100, 'PIVKA_100'] = 0\n",
    "df.loc[~(df['PIVKA'] < 100), 'PIVKA_100'] = 1\n",
    "df['PIVKA_100'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-nature",
   "metadata": {},
   "source": [
    "## Vp_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vp_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['Vp_grade'].isnull().sum()\n",
    "df['Vp_grade'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-contact",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Vp_grade'] = df['Vp_grade'].replace(2,  1).replace(3, 1).replace(4, 1)\n",
    "df['Vp_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-magnitude",
   "metadata": {},
   "source": [
    "## meta_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Meta0or1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['Meta0or1'].isnull().sum()\n",
    "df['Meta0or1'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Meta0or1'])\n",
    "df['Meta0or1'] = df['Meta0or1'].replace(2, 1).astype(int)\n",
    "df['Meta0or1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-share",
   "metadata": {},
   "source": [
    "## etiology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['etiology_C1B2BC3Alc4NBNC5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += df['etiology_C1B2BC3Alc4NBNC5'].isnull().sum()\n",
    "df['etiology_C1B2BC3Alc4NBNC5'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['etiology_C1B2BC3Alc4NBNC5'])\n",
    "df = df.rename(columns={'etiology_C1B2BC3Alc4NBNC5': 'etiology_class'})\n",
    "df['etiology_class'] = df['etiology_class'].replace(1,  'C').replace(2, 'B').replace(3, 'BC').replace(4, 'Alc').replace(5, 'NBNC')\n",
    "df['etiology_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['etiology_class'])\n",
    "df.loc[df['etiology_class_BC'] == 1, 'etiology_class_B'] = 1\n",
    "df.loc[df['etiology_class_BC'] == 1, 'etiology_class_C'] = 1\n",
    "df = df.drop(columns=['etiology_class_BC', 'etiology_class_NBNC'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-wrestling",
   "metadata": {},
   "source": [
    "## OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OS_day'] = df['OS_day'].replace('#VALUE!', np.nan).replace('#REF!', np.nan)\n",
    "cut += df['OS_day'].isnull().sum()\n",
    "df['OS_day'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['OS_day'])\n",
    "df['OS_day'] = df['OS_day'].astype(int)\n",
    "df['OS_day'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-migration",
   "metadata": {},
   "source": [
    "## 肝臓がんのみを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-bidder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['肝癌症例'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut += len(df[df['肝癌症例']==0])\n",
    "len(df[df['肝癌症例']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['肝癌症例'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-diabetes",
   "metadata": {},
   "source": [
    "## dfとcutの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-throw",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-booking",
   "metadata": {},
   "source": [
    "## Three_Yearの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Death1Alive0'] = df['Death1Alive0'].astype(int)\n",
    "df.insert(loc=0, column='Three_Year', value= -1)\n",
    "df.loc[(df['OS_day'] < 1095) & (df['Death1Alive0'] == 1), 'Three_Year'] = 0\n",
    "df.loc[df['OS_day'] >= 1095, 'Three_Year'] = 1\n",
    "df['Three_Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3年後の生死が未確認（OS.day<1095&Death1Alive0=0)を削除\n",
    "df = df[df['Three_Year'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-milan",
   "metadata": {},
   "source": [
    "## 学習データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-telescope",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df.loc[:,['Ablation', 'OPE', 'TAE', 'MTA', 'Radiation', 'Last_Treatment', 'Age', 'Gender', 'BMI_NN', 'No_of_Admission', 'HCC_No', 'No_Cumsum', \n",
    "                 'HCC_size', 'NoSize', 'NoSize_Cumsum', 'PS_Raw', 'ALBI_score', 'AFP_100', 'L3_10', 'PIVKA_100', \n",
    "                 'Vp_grade', 'Meta0or1', 'etiology_class_C', 'etiology_class_B', 'etiology_class_Alc']]\n",
    "target = df['Three_Year']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-prisoner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-logan",
   "metadata": {},
   "source": [
    "# TrainとValidの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target, train_size = 0.8, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-karen",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_inv = np.linalg.inv(np.array(x_train.corr()))\n",
    "vif = pd.Series(np.diag(corr_inv), index=x_train.columns)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-closure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop('No_Cumsum', axis=1)\n",
    "x_train_columns = x_train.columns.values.tolist()\n",
    "print(x_train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = x_train.join(y_train)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepAIC(descs_l):\n",
    "    import copy\n",
    "    descriptors = descs_l\n",
    "    f_model = smf.glm(formula='Three_Year ~ ' + ' + '.join(descriptors),\n",
    "                      data=train_data, family=sm.families.Binomial()).fit()\n",
    "    best_aic = f_model.aic\n",
    "    best_model = f_model\n",
    "    while descriptors:\n",
    "        desc_selected = ''\n",
    "        flag = 0\n",
    "        for desk in descriptors:\n",
    "            used_desks = copy.deepcopy(descriptors)\n",
    "            used_desks.remove(desk)\n",
    "            formula = 'Three_Year ~ ' + ' + '.join(used_desks)\n",
    "            model = smf.glm(formula=formula, \n",
    "                            data=train_data, family=sm.families.Binomial()).fit()\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_model = model\n",
    "                desc_selected = desk\n",
    "                flag = 1\n",
    "        if flag:\n",
    "            descriptors.remove(desc_selected)\n",
    "        else:\n",
    "            break\n",
    "    return best_model\n",
    " \n",
    "model = stepAIC(x_train_columns)\n",
    "print(model.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame({'model': model.predict()})\n",
    "ddf['model_p'] = ddf.model.map(lambda x: 1 if x >= 0.5 else 0)\n",
    "ddf['exp'] = np.array(train_data.Three_Year)\n",
    " \n",
    "correct_count = len(ddf[ ddf.model_p == ddf.exp ])\n",
    "print(correct_count)\n",
    "print(correct_count/len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "cm = confusion_matrix(train_data.Three_Year, ddf.model_p)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = np.zeros(len(train_data))\n",
    "for i,j in zip(model.params.index, model.params.values):\n",
    "    if i == 'Intercept':\n",
    "        eq += np.array([j])\n",
    "    else:\n",
    "        eq += j*np.array(train_data[i])\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(eq, train_data.Three_Year, marker='o', alpha=0.3)\n",
    "ax.plot(np.sort(eq), 1/(1+(np.exp(-np.sort(eq)))), 'k-', lw=2)\n",
    "ax.set_ylabel('Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.model_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC曲線の値の生成：fpr、tpr、閾値\n",
    "fpr, tpr, thresholds = roc_curve(ddf.exp, ddf.model)\n",
    "\n",
    "# ROC曲線のプロット\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "#plt.savefig('results/0111_Test_ROC_3year.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "#AUCの表示\n",
    "auc_GLM = roc_auc_score(ddf.exp, ddf.model)\n",
    "print(auc_GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_ci(y_true, y_score, positive=1):\n",
    "    AUC = roc_auc_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = math.sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, upper)\n",
    "\n",
    "roc_auc_ci(ddf.exp, ddf.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _proportion_confidence_interval(r, n, z):\n",
    "    A = 2*r + z**2\n",
    "    B = z*math.sqrt(z**2 + 4*r*(1 - r/n))\n",
    "    C = 2*(n + z**2)\n",
    "    return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "def sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha):\n",
    "    \n",
    "    z = -ndtri((1.0-alpha)/2)\n",
    "    \n",
    "    sensitivity_point_estimate = TP/(TP + FN)\n",
    "    sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "    \n",
    "    specificity_point_estimate = TN/(TN + FP)\n",
    "    specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "    \n",
    "    return sensitivity_point_estimate, specificity_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval\n",
    "\n",
    "sensitivity_and_specificity_with_confidence_intervals(cm[1][1], cm[0][1], cm[1][0], cm[0][0], 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_calibration_curve(y_test, y_pred, name):\n",
    "    frac_of_pos, mean_pred_value = calibration_curve(y_test, y_pred, n_bins=10)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,6))\n",
    "    ax[0].plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    ax[0].plot(mean_pred_value, frac_of_pos, marker=\"o\", label=f'{name}')\n",
    "    ax[0].set_ylabel(\"Fraction of positives\")\n",
    "    ax[0].set_ylim([-0.05, 1.05])\n",
    "    ax[0].legend(loc=\"lower right\")\n",
    "    ax[0].set_title(f'Calibration plot 1year ({name})')\n",
    "    \n",
    "    sns.distplot(y_pred, bins=100, label='predicted score', ax=ax[1])\n",
    "    ax[1].legend(loc='upper right')\n",
    "    ax[1].set_xlim([-0.05, 1.05])\n",
    "    #plt.savefig('results/0111_calibration_3year.jpg', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# AUCとReliability Diagramの可視化\n",
    "viz_calibration_curve(ddf.exp, ddf.model, 'GLM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model, open('models/0111_model_GLM_3year.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-application",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
